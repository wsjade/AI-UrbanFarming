{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense , Flatten , Conv2D , MaxPooling2D , Dropout , Activation , BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam , Adamax\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "import os\n",
    "\n",
    "\n",
    "#Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras import backend as K\n",
    "\n",
    "# def clear_memory():\n",
    "#     K.clear_session()\n",
    "#     tf.keras.backend.clear_session()\n",
    "#     import gc\n",
    "#     gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data= \"C:/Users/User/OneDrive/Documents/FYP/Computer_Vision_FYP/Codes/data/raw/plantvillage dataset/edited\"\n",
    "\n",
    "def create_dataframe(data_path):\n",
    "    # List to store filepaths and labels\n",
    "    filepaths = []\n",
    "    labels = []\n",
    "\n",
    "    # List all subfolders in the current data path\n",
    "    folds = os.listdir(data_path)\n",
    "    \n",
    "    # Iterate through each subfolder\n",
    "    for fold in folds:\n",
    "        f_path = os.path.join(data_path, fold)\n",
    "        imgs = os.listdir(f_path)\n",
    "        \n",
    "        # Iterate through images in the subfolder\n",
    "        for img in imgs:\n",
    "            img_path = os.path.join(f_path, img)\n",
    "            \n",
    "            # Append image path and corresponding label\n",
    "            filepaths.append(img_path)\n",
    "            labels.append(fold)\n",
    "\n",
    "    # Create Pandas Series for filepaths and labels\n",
    "    fseries = pd.Series(filepaths, name='Filepaths')\n",
    "    lseries = pd.Series(labels, name='Labels')\n",
    "\n",
    "    # Concatenate into a DataFrame and return\n",
    "    return pd.concat([fseries, lseries], axis=1)\n",
    "\n",
    "# Create DataFrames for train, test, and val\n",
    "df = create_dataframe(data)\n",
    "\n",
    "# Check the number of images in each class\n",
    "class_counts = df['Labels'].value_counts()\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the class distribution\n",
    "class_counts = df['Labels'].value_counts()\n",
    "plt.figure(figsize=(12,8))\n",
    "class_counts.plot(kind='bar')\n",
    "plt.title('Number of Images per Class')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Define the output directory and train_test_split dir\n",
    "output_dir = \"C:/Users/User/OneDrive/Documents/FYP/Computer_Vision_FYP/Codes/data/processed\"\n",
    "train_test_valid_dir = \"C:/Users/User/OneDrive/Documents/FYP/Computer_Vision_FYP/Codes/data/raw\"\n",
    "\n",
    "# Create train, valid, and test directories within the output directory\n",
    "train_dir = os.path.join(train_test_valid_dir, 'train')\n",
    "valid_dir = os.path.join(train_test_valid_dir, 'valid')\n",
    "test_dir = os.path.join(train_test_valid_dir, 'test')\n",
    "\n",
    "# Function to check if directories are empty\n",
    "def are_directories_empty(directories):\n",
    "    return all(not os.listdir(directory) for directory in directories)\n",
    "\n",
    "# Check if the directories already contain files\n",
    "directories_to_check = [train_dir, valid_dir, test_dir]\n",
    "\n",
    "if are_directories_empty(directories_to_check):\n",
    "    # If directories are empty, proceed with splitting and saving images\n",
    "    # Assuming df is already defined and contains your data\n",
    "    train_df, dummy_df = train_test_split(df, train_size=0.8, shuffle=True, random_state=42)\n",
    "    valid_df, test_df = train_test_split(dummy_df, train_size=0.5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Save images to directory function\n",
    "    def save_images(df, base_dir):\n",
    "        for index, row in df.iterrows():\n",
    "            label = row['Labels']\n",
    "            filepath = row['Filepaths']\n",
    "\n",
    "            # Create class directory if it doesn't exist\n",
    "            class_dir = os.path.join(base_dir, label)\n",
    "            os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "            # Copy image to the target directory\n",
    "            shutil.copy(filepath, class_dir)\n",
    "\n",
    "    # Save images to corresponding directories\n",
    "    save_images(train_df, train_dir)\n",
    "    save_images(valid_df, valid_dir)\n",
    "    save_images(test_df, test_dir)\n",
    "\n",
    "    print(\"Images have been successfully split and saved into the processed directory.\")\n",
    "else:\n",
    "    print(\"Data already exists in the directories. Skipping the split and save process.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "\n",
    "# Define paths\n",
    "output_dir = \"C:/Users/User/OneDrive/Documents/FYP/Computer_Vision_FYP/Codes/data/processed\"\n",
    "\n",
    "threshold = 1200  # Set your threshold for number of images\n",
    "\n",
    "# Define ImageDataGenerator for augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Count number of images in the directory\n",
    "def count_images_in_dir(directory):\n",
    "    total_images = 0\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                total_images += 1\n",
    "    return total_images\n",
    "\n",
    "# Process each label within train directory\n",
    "for label in os.listdir(train_dir):\n",
    "    original_class_dir = os.path.join(train_dir, label)\n",
    "    class_save_dir = os.path.join(output_dir, label)\n",
    "    \n",
    "    if not os.path.exists(original_class_dir):\n",
    "        print(f\"Original class directory '{original_class_dir}' does not exist.\")\n",
    "        continue\n",
    "\n",
    "    # Count images in directory\n",
    "    original_count = count_images_in_dir(original_class_dir)\n",
    "    augmented_count = count_images_in_dir(class_save_dir)\n",
    "    total_count = original_count + augmented_count\n",
    "\n",
    "    print(f\"Original images for class '{label}': {original_count}\")\n",
    "    print(f\"Augmented images for class '{label}': {augmented_count}\")\n",
    "    print(f\"Total images for class '{label}': {total_count}\")\n",
    "    \n",
    "    # test if total count is higher than threshold.\n",
    "    # If yes, move on\n",
    "    # if no, continue with augementation\n",
    "    if total_count >= threshold:\n",
    "        print(f\"Class '{label}' already has enough images. Skipping augmentation.\")\n",
    "        continue\n",
    "    \n",
    "    # calculate number of images to generate\n",
    "    num_to_generate = threshold - total_count\n",
    "    print(f\"Number of images to generate for class '{label}': {num_to_generate}\")\n",
    "    \n",
    "    # generate if number to generate is more than 0\n",
    "    if num_to_generate > 0:\n",
    "        print(f\"Augmenting class '{label}' to reach {threshold} images.\")\n",
    "        \n",
    "        os.makedirs(class_save_dir, exist_ok=True)\n",
    "        \n",
    "        # Use ImageDataGenerator to generate augmented images\n",
    "        generator = train_datagen.flow_from_directory(\n",
    "            train_dir,\n",
    "            target_size=(128, 128),  # Adjust size as needed\n",
    "            batch_size=1,\n",
    "            class_mode=None,  # No labels\n",
    "            save_to_dir=class_save_dir,\n",
    "            save_prefix='aug',\n",
    "            save_format='jpeg',\n",
    "            classes=[label]  # Only process images from the specific class\n",
    "        )\n",
    "        \n",
    "        num_images_processed = 0\n",
    "        \n",
    "        while num_images_processed < num_to_generate:\n",
    "            batch = next(generator)\n",
    "            num_images_processed += len(batch)\n",
    "            if num_images_processed >= num_to_generate:\n",
    "                break\n",
    "        \n",
    "        print(f\"Augmentation for class '{label}' completed. {num_images_processed} images generated.\")\n",
    "    else:\n",
    "        print(f\"Class '{label}' does not need additional augmentation.\")\n",
    "\n",
    "print(\"Data augmentation completed and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define combined directory\n",
    "combined_dir = \"C:/Users/User/OneDrive/Documents/FYP/Computer_Vision_FYP/Codes/data/combined\"\n",
    "\n",
    "# Create combined directory if it doesn't exist\n",
    "if not os.path.exists(combined_dir):\n",
    "    os.makedirs(combined_dir)\n",
    "\n",
    "# Function to copy images and avoid duplicates\n",
    "def copy_images(source_dir, target_dir):\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "    \n",
    "    for file in os.listdir(source_dir):\n",
    "        src_file = os.path.join(source_dir, file)\n",
    "        tgt_file = os.path.join(target_dir, file)\n",
    "        \n",
    "        # Check if the file already exists in the target directory\n",
    "        if not os.path.exists(tgt_file):\n",
    "            print(f\"Copying {src_file} to {tgt_file}\")\n",
    "            shutil.copy(src_file, tgt_file)\n",
    "        else:\n",
    "            print(f\"File {tgt_file} already exists.\")\n",
    "\n",
    "# Copy original images from trained_dir to the combined directory\n",
    "for label in os.listdir(train_dir):\n",
    "    label_dir = os.path.join(train_dir, label)\n",
    "    if os.path.isdir(label_dir):\n",
    "        target_label_dir = os.path.join(combined_dir, label)\n",
    "        copy_images(label_dir, target_label_dir)\n",
    "\n",
    "# Copy augmented images from output_dir to the combined directory\n",
    "for label in os.listdir(output_dir):\n",
    "    label_dir = os.path.join(output_dir, label)\n",
    "    if os.path.isdir(label_dir):\n",
    "        target_label_dir = os.path.join(combined_dir, label)\n",
    "        copy_images(label_dir, target_label_dir)\n",
    "\n",
    "print(\"Images combined into the directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the path to the combined directory\n",
    "combined_dir = \"C:/Users/User/OneDrive/Documents/FYP/Computer_Vision_FYP/Codes/data/combined\"\n",
    "\n",
    "# Function to count images in each class\n",
    "def count_images_in_classes(directory):\n",
    "    class_counts = {}\n",
    "    \n",
    "    for label in os.listdir(directory):\n",
    "        label_dir = os.path.join(directory, label)\n",
    "        if os.path.isdir(label_dir):\n",
    "            num_images = len([file for file in os.listdir(label_dir) if file.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "            class_counts[label] = num_images\n",
    "    \n",
    "    return class_counts\n",
    "\n",
    "# Get the counts of images in each class\n",
    "class_counts = count_images_in_classes(combined_dir)\n",
    "\n",
    "# Print the number of classes and the number of images in each class\n",
    "print(f\"Total number of classes: {len(class_counts)}\\n\")\n",
    "for label, count in class_counts.items():\n",
    "    print(f\"Class '{label}' has {count} images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# import os\n",
    "# import random\n",
    "# import numpy as np\n",
    "\n",
    "# def undersample_class(directory, target_num_images):\n",
    "#     for label in os.listdir(directory):\n",
    "#         label_dir = os.path.join(directory, label)\n",
    "#         if os.path.isdir(label_dir):\n",
    "#             images = [f for f in os.listdir(label_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "#             if len(images) > target_num_images:\n",
    "#                 selected_images = random.sample(images, target_num_images)\n",
    "#                 for image in images:\n",
    "#                     if image not in selected_images:\n",
    "#                         os.remove(os.path.join(label_dir, image))\n",
    "\n",
    "\n",
    "# # Count the number of images in each class directory\n",
    "# def count_images_in_dir(directory):\n",
    "#     total_images = 0\n",
    "#     for root, dirs, files in os.walk(directory):\n",
    "#         for file in files:\n",
    "#             if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "#                 total_images += 1\n",
    "#     return total_images\n",
    "\n",
    "# # Initialize a dictionary to store class counts\n",
    "# new_class_count = {}\n",
    "\n",
    "# # Iterate over each class directory in the combined directory\n",
    "# for label in os.listdir(combined_dir):\n",
    "#     label_dir = os.path.join(combined_dir, label)\n",
    "#     if os.path.isdir(label_dir):\n",
    "#         # Count the number of images in the current class directory\n",
    "#         class_count = count_images_in_dir(label_dir)\n",
    "#         new_class_count[label] = class_count\n",
    "#         print(f\"Class '{label}' has {class_count} images.\")\n",
    "\n",
    "# # Convert new_class_count to a list of counts if it's a dictionary\n",
    "# if isinstance(new_class_count, dict):\n",
    "#     new_class_count = list(new_class_count.values())\n",
    "\n",
    "# # Find the minimum number of images among all classes\n",
    "# target_num_images = min(new_class_count) if new_class_count else 0\n",
    "# print(f\"Target number of images for undersampling: {target_num_images}\")\n",
    "\n",
    "# # Undersample classes if necessary\n",
    "# undersample_class(combined_dir, target_num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ImageDataGenerator for training\n",
    "train_datagens = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Set up the generator to read from the combined directory\n",
    "train_generator = train_datagens.flow_from_directory(\n",
    "    directory=combined_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Load validation and test data\n",
    "valid_generator = valid_datagen.flow_from_dataframe(\n",
    "    dataframe=valid_df,\n",
    "    x_col='Filepaths',\n",
    "    y_col='Labels',\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='Filepaths',\n",
    "    y_col='Labels',\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import pandas as pd\n",
    "\n",
    "# Get class labels from the generator\n",
    "class_indices = train_generator.class_indices\n",
    "class_labels = list(class_indices.keys())\n",
    "\n",
    "# Initialize a dictionary to count the number of samples for each class\n",
    "class_counts = {class_name: 0 for class_name in class_labels}\n",
    "\n",
    "# Iterate over the batches to count the number of samples in each class\n",
    "for batch in train_generator:\n",
    "    x_batch, y_batch = batch\n",
    "    # Count occurrences of each class in the batch\n",
    "    y_batch_classes = np.argmax(y_batch, axis=1)\n",
    "    unique, counts = np.unique(y_batch_classes, return_counts=True)\n",
    "    for cls, count in zip(unique, counts):\n",
    "        class_counts[class_labels[cls]] += count\n",
    "    \n",
    "    # Stop after one epoch (or adjust based on your needs)\n",
    "    break\n",
    "\n",
    "# Calculate class weights\n",
    "total_samples = sum(class_counts.values())\n",
    "num_classes = len(class_counts)\n",
    "class_weights = {i: total_samples / (num_classes * class_counts[class_name]) for i, class_name in enumerate(class_labels)}\n",
    "\n",
    "print('Class Weights:', class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam , SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Define base model\n",
    "base_model = tf.keras.applications.Xception(weights='imagenet', include_top=False, input_shape=(128, 128, 3), pooling='max')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    BatchNormalization(),\n",
    "    Dense(256, activation='relu', kernel_regularizer=l2(0.01)),  \n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.0001, clipvalue=1.0)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('Xception_best_model.h5', save_best_only=True, monitor='val_loss')\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.3,  # Factor by which the learning rate will be reduced\n",
    "    patience=5,  # Number of epochs with no improvement after which learning rate will be reduced\n",
    "    min_lr=1e-7  # Minimum learning rate\n",
    ")\n",
    "\n",
    "\n",
    "# clear_memory()\n",
    "\n",
    "# Training\n",
    "history = model.fit(\n",
    "    x=train_generator,\n",
    "    validation_data=valid_generator,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=1,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stopping, model_checkpoint, lr_scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# base_model = tf.keras.applications.Xception(weights= 'imagenet' ,include_top = False , input_shape = (128,128,3) ,\n",
    "#                                                      pooling = 'max' )\n",
    "\n",
    "# # Define the model\n",
    "# model = Sequential([\n",
    "#     base_model,\n",
    "#     BatchNormalization(),\n",
    "#     Dense(256, activation='relu', kernel_regularizer=l2(0.01)),  \n",
    "#     Dropout(0.5),\n",
    "#     Dense(10, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# optimizer = Adam(learning_rate=1e-5)\n",
    "\n",
    "# model.compile(optimizer=optimizer , loss = 'categorical_crossentropy' , metrics= ['accuracy'])\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "# model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss')\n",
    "\n",
    "# lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 0.0001 * 0.9 ** epoch)\n",
    "\n",
    "# batch_size = 32\n",
    "\n",
    "# tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# history = model.fit(\n",
    "#     x=train_generator,\n",
    "#     validation_data=valid_generator,\n",
    "#     epochs=10,  # Start with a smaller number of epochs\n",
    "#     batch_size=batch_size,\n",
    "#     verbose=1,\n",
    "#     callbacks=[early_stopping, model_checkpoint, lr_scheduler]\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model\n",
    "model.save('C:/Users/User/OneDrive/Documents/FYP/Computer_Vision_FYP/Codes/models/Xception_model.h5')\n",
    "\n",
    "# Save the history\n",
    "with open('C:/Users/User/OneDrive/Documents/FYP/Computer_Vision_FYP/Codes/history/Xception_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Load the model\n",
    "loaded_model = keras.models.load_model('C:/Users/User/OneDrive/Documents/FYP/Computer_Vision_FYP/Codes/models/Xception_model.h5')\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_probs = loaded_model.predict(test_generator)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)  # Convert probabilities to class labels\n",
    "\n",
    "# Get true labels\n",
    "y_true = test_generator.classes  # or obtain from test_generator\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_true, y_pred, target_names=test_generator.class_indices.keys())\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Open the file in read mode to load the history\n",
    "with open('C:/Users/User/OneDrive/Documents/FYP/Computer_Vision_FYP/Codes/history/Xception_history.pkl', 'rb') as f:\n",
    "    history = pickle.load(f)\n",
    "\n",
    "# Now you can access the history data\n",
    "tr_acc = history['accuracy']\n",
    "tr_loss = history['loss']\n",
    "val_acc = history['val_accuracy']\n",
    "val_loss = history['val_loss']\n",
    "\n",
    "epochs = [i + 1 for i in range(len(tr_acc))]\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, tr_loss, 'r', label='Train Loss')\n",
    "plt.plot(epochs, val_loss, 'g', label='Valid Loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, tr_acc, 'r', label='Train Accuracy')\n",
    "plt.plot(epochs, val_acc, 'g', label='Valid Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics\n",
    "test_loss, test_accuracy = loaded_model.evaluate(test_generator)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", test_accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=test_generator.class_indices.keys(), yticklabels=test_generator.class_indices.keys())\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_indices = test_generator.class_indices\n",
    "class_labels = {v: k for k, v in class_indices.items()}  # Invert the dictionary\n",
    "\n",
    "# Displaying a few sample predictions with their true labels\n",
    "def display_predictions(generator, model, num_images=5):\n",
    "    x_test, y_test = next(generator)  # Get a batch of images and labels\n",
    "    predictions = model.predict(x_test)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(1, num_images, i+1)\n",
    "        plt.imshow(x_test[i])\n",
    "        true_label = class_labels[true_classes[i]]\n",
    "        pred_label = class_labels[predicted_classes[i]]\n",
    "        plt.title(f\"True: {true_label}\\nPred: {pred_label}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Display predictions for the first batch of test data\n",
    "display_predictions(test_generator, loaded_model, num_images=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
